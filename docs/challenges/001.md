# Redis 다층 캐싱 전략

## 1. 문제 상황

스냅링크는 URL 단축 서비스로, 가장 핵심 기능인 단축 URL 리다이렉트에 대한 빠른 응답 시간이 필수적이었습니다. 초기 구현에서는 모든 요청이 데이터베이스를 직접 조회하면서 다음과 같은 문제가 발생했습니다:

- 리다이렉트 응답 시간이 평균 46ms로 느림
- 데이터베이스에 과도한 부하 집중
- 동시 접속자 증가 시 성능 저하 발생

특히 서비스의 특성상 읽기:쓰기 비율이 100:1에 달하는 워크로드 패턴을 보였습니다. 즉, 단축 URL 생성은 드물게 발생하지만 리다이렉트는 매우 빈번하게 발생하는 상황이었습니다.

## 2. 해결 방법

이러한 문제를 해결하기 위해 Redis를 활용한 다층 캐싱 전략을 구현했습니다.

### 2.1 Spring Cache 추상화 계층 활용

`CacheConfig.java`에서 Spring의 캐싱 추상화 계층을 구성하여 애플리케이션 코드와 캐싱 인프라를 분리했습니다:

```java
@Configuration
@EnableCaching
public class CacheConfig extends CachingConfigurerSupport {
    @Bean
    public CacheManager cacheManager(RedisConnectionFactory connectionFactory,
                                     @Qualifier("redisObjectMapper") ObjectMapper mapper) {
        // 캐시별 설정
        Map<String, RedisCacheConfiguration> cacheConfigurations = new HashMap<>();
        cacheConfigurations.put("urls", defaultConfig.entryTtl(Duration.ofDays(1)));
        cacheConfigurations.put("stats", defaultConfig.entryTtl(Duration.ofMinutes(30)));

        return RedisCacheManager.builder(connectionFactory)
                .cacheDefaults(defaultConfig)
                .withInitialCacheConfigurations(cacheConfigurations)
                .build();
    }
}
```

### 2.2 데이터 접근 패턴 분석 기반 캐싱 전략

서비스의 읽기:쓰기 비율(100:1)을 분석하여, 읽기 작업에 최적화된 캐싱 전략을 수립했습니다:

1. **URL 조회 캐싱**: 가장 빈번한 단축 코드 → 원본 URL 변환 작업을 캐싱
2. **데이터 특성별 캐시 분리**:
    - URL 정보는 변경이 적어 1일의 긴 TTL 적용
    - 통계 정보는 자주 변경되므로 30분의 짧은 TTL 적용

### 2.3 선언적 캐싱 적용

`UrlService.java`에서 Spring의 캐시 어노테이션을 활용하여 핵심 메서드의 결과를 캐싱했습니다:

```java
@Override
@Cacheable(value = "urls", key = "#shortCode", unless = "#result == null")
public Url getUrlByShortCode(String shortCode) {
    return urlRepository.findActiveByShortCode(shortCode)
            .orElseThrow(() -> UrlNotFoundException.EXCEPTION);
}

@Override
@Transactional
@CachePut(value = "urls", key = "#shortCode")
public Url incrementClickCount(String shortCode) {
    urlRepository.incrementClickCount(shortCode);
    return getUrlByShortCode(shortCode);
}
```

이를 통해 코드 변경 없이도 캐싱 기능을 적용할 수 있었고, 비즈니스 로직과 캐싱 로직을 분리할 수 있었습니다.

### 2.4 캐시 워밍업 전략 구현

서비스 시작 시 빈 캐시로 인한 초기 성능 저하를 방지하기 위해, 자주 접근되는 URL을 미리 캐시에 로드하는 워밍업 전략을 구현했습니다:

```java
@Scheduled(fixedRate = 3600000) // 1시간마다 실행
public void preloadHotUrls() {
    List<Url> hotUrls = urlRepository.findTopUrlsByClickCount(10);
    Cache cache = cacheManager.getCache("urls");
    if (cache != null) {
        hotUrls.forEach(url -> cache.put(url.getShortCode(), url));
    }
}
```

이를 통해 서비스 재시작 후에도 캐시 히트율을 빠르게 높일 수 있었습니다.

### 2.5 Write-Through 패턴으로 캐시 일관성 보장

데이터 변경 시 캐시와 데이터베이스의 일관성을 유지하기 위해 Write-Through 패턴을 적용했습니다:

1. 먼저 데이터베이스를 업데이트
2. 성공 시 캐시도 함께 업데이트 (`@CachePut` 활용)

```java
@Transactional
@CachePut(value = "urls", key = "#shortCode")
public Url incrementClickCount(String shortCode) {
    // 1. 먼저 DB 업데이트
    urlRepository.incrementClickCount(shortCode);
    // 2. 업데이트된 엔티티 조회 및 캐시 갱신
    return getUrlByShortCode(shortCode);
}
```

또한, 만료된 URL을 자동으로 캐시에서 제거하는 스케줄링 작업도 구현했습니다:

```java
@Scheduled(fixedRate = 86400000) // 24시간마다 실행
public void evictExpiredUrls() {
    List<Url> expiredUrls = urlRepository.findByExpiresAtBefore(LocalDateTime.now());
    Cache cache = cacheManager.getCache("urls");
    if (cache != null) {
        expiredUrls.forEach(url -> cache.evict(url.getShortCode()));
    }
}
```

### 2.6 Redis Pipeline 활용으로 네트워크 왕복 최소화

통계 조회 시 여러 데이터를 한 번에 가져오기 위해 Redis Pipeline을 활용했습니다:

```java
public Map<String, Long> getAllStats(String shortCode) {
    // Redis Pipeline으로 여러 명령 일괄 처리
    List<Object> results = stringRedisTemplate.executePipelined(new RedisCallback<Object>() {
        @Override
        public Object doInRedis(RedisConnection connection) {
            StringRedisConnection stringConn = (StringRedisConnection) connection;
            // 여러 명령을 한 번의 네트워크 왕복으로 처리
            stringConn.get(clicksKey);
            stringConn.get(dailyKey);
            stringConn.hGetAll(browserKey);
            return null;
        }
    });
    
    // 결과 처리
    // ...
}
```

이를 통해 여러 Redis 명령을 단일 네트워크 왕복으로 처리하여 응답 시간을 더욱 단축했습니다.

### 2.7 정밀한 성능 모니터링

캐싱 전략의 효과를 지속적으로 모니터링하기 위해 상세한 메트릭을 수집했습니다:

```java
@PostConstruct
public void setupCacheHitRatioGauge() {
    Gauge.builder("cache.hit.ratio", this, service -> calculateCacheHitRatio())
            .description("캐시 히트율")
            .register(meterRegistry);
}

private double calculateCacheHitRatio() {
    double hits = meterRegistry.find("cache.hits").counter().count();
    double misses = meterRegistry.find("cache.misses").counter().count();
    double total = hits + misses;
    return total > 0 ? hits / total : 0;
}
```

이렇게 수집된 메트릭은 Prometheus와 Grafana를 통해 시각화하여 캐싱 전략의 효과를 실시간으로 확인했습니다.

## 3. 결과

Redis 다층 캐싱 전략 적용 후 다음과 같은 성과를 달성했습니다:

- **리다이렉트 응답 시간**: 46ms → 4ms (91.3% 감소)
- **데이터베이스 부하**: 90% 이상 감소
- **캐시 히트율**: 99.94% 달성
- **서비스 안정성**: 오류율 73.6% 감소

특히 핵심 기능인 URL 리다이렉트의 응답 시간이 대폭 개선되어 사용자 경험이 크게 향상되었습니다.

## 4. 한계점 및 향후 개선 방향

현재 Redis 캐싱 전략에는 몇 가지 한계점과 개선 가능성이 있습니다:

**접근 빈도 기반 동적 TTL 조정**: 현재는 캐시 유형별로 고정된 TTL을 사용하고 있습니다. 리드미에 언급된 "접근 빈도에 따른 동적 TTL 조정"을 실제로 구현하면 캐시 효율성을 더욱 높일 수 있을 것입니다. 자주 접근되는 URL은 TTL을 더 길게, 드물게 접근되는 URL은 짧게 설정하는 전략이 효과적일 것입니다.

**Redis Cluster 도입**: 현재는 단일 Redis 서버를 사용하고 있어 확장성과 고가용성에 제한이 있습니다. 서비스 규모가 확장됨에 따라 Redis Cluster를 도입하여 부하 분산 및 장애 대응 능력을 강화할 필요가 있습니다.

Redis 다층 캐싱 전략은 스냅링크의 성능을 획기적으로 향상시켰으며, 특히 읽기 작업이 많은 워크로드 특성을 가진 서비스에 매우 효과적이었습니다.